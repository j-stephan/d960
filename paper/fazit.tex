\section{Fazit}

\subsection{Entwicklungsstand}

Es wurde gezeigt, dass Texterkennung in und -extraktion aus topographischen Karten mit der vorgestellten
Netzwerkarchitektur möglich ist und gute Erkennungsraten liefert. Vorbedingung dafür ist das Vorliegen einer genügend
großen Datenmenge für das \textit{Training}, da das Netzwerk ansonsten zu \textit{Overfitting} neigt. Künstliche
\textit{Trainings}-Daten sind daher für ein funktionierendes Netzwerk essentiell.

Die Nutzung der Frameworks \textit{Keras} und \textit{TensorFlow} ermöglichte eine einfache Umsetzung für die Nutzung
der auf dem HPC-System \textit{Taurus} vorhandenen GPUs.

\subsection{Ausblick}

Insbesondere die Gewinnung den historischen Schriftbildern entsprechender \textit{Trainings}-Daten gestaltete sich
schwierig. In seiner aktuellen Fassung behilft sich der Datengenerator mit aus dem vorliegenden Kartenmaterial
ausgeschnittenen Einzelbuchstaben, die dann aneinandergereiht werden; die Alternative besteht im mühevollen manuellen
Ausschneiden der ganzen Wörter, wie es für diese Arbeit für die in Abschnitt~\ref{ergebnisse:daten} erwähnten
Validierungsdaten getan wurde.

Eine Verbesserung dieser Situation sowie daraus folgend der \textit{Inferenz}-Ergebnisse ließe sich vermutlich durch
den Einsatz der Schriftarten \textit{Kursivschrift} (vgl.~\cite{kursivschrift}) und \textit{Roemisch}
(vgl.~\cite{roemisch}) innerhalb des Datengenerators erreichen, da sie den historisch genutzten Schriftarten
weitestgehend entsprechen.

Ein weiterer Ansatz zur Verbesserung der Erkennungsrate könnte darin liegen, Vorder- und Hintergrund, das heißt Text
und Karte, voneinander zu trennen und getrennt auszuwerten.

Zu untersuchen wäre ferner, inwieweit sich ein Netzwerk, das bereits auf ein ähnlich gelagertes Problem angelernt
wurde (wie etwa die Texterkennung in Fotografien), im Rahmen von \textit{Transfer Learning} für die Texterkennung in
topographischen Karten verwenden lässt.

Schließlich wäre eine verbesserte \textit{Score}-Berechnung wünschenswert, die auch Sonderfälle wie die in
Abschnitt~\ref{ergebnisse:erfolg} genannten berücksichtigen kann.

Hinsichtlich des Laufzeitverhaltens steht eine genauere Untersuchung der effizienten Nutzung mehrerer GPUs aus. Eine
solche Erhöhung des Parallelisierungsgrades ist aufgrund der Dauer des \textit{Trainings} wünschenswert und wird von
\textit{Keras} und \textit{TensorFlow} prinzipiell unterstützt (\textit{Keras} bietet hier das
\texttt{multi\_gpu\_model}-API). Erste Testläufe dazu haben bereits stattgefunden, es sind jedoch für einen effizienten
Multi-GPU-Ansatz weitere Arbeiten notwendig.
